{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##???\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install categorical_embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import categorical_embedder as ce\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "df = pd.read_csv('../data/raw/beer_reviews.csv')\n",
    "#Load saved processed data\n",
    "#traindf = pd.read_csv('../data/processed/traindf.csv')\n",
    "#target = pd.read_csv('../data/processed/target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDA\n",
    "#df.head()\n",
    "#df.info()\n",
    "#df.describe()\n",
    "#df.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find out how many different labels we are predicting\n",
    "#df.brewery_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualisations\n",
    "\n",
    "#boxplot = df.boxplot(column=['review_overall', 'review_aroma', 'review_appearance','review_palate','review_taste'])\n",
    "#boxplot_abv = df.boxplot(column=['beer_abv'])\n",
    "\n",
    "#df.hist(column=['review_overall', 'review_aroma', 'review_appearance','review_palate','review_taste'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare data  - removed inplace=True as it wasn't saving to csv\n",
    "traindf = df.copy()\n",
    "traindf = traindf.dropna()\n",
    "traindf.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-processing: Scaling. (Can turn this into a pipeline - after standardscaler, some reviews turned negative\n",
    "##cat_cols = ['brewery_name']\n",
    "num_cols = ['review_overall', 'review_aroma', 'review_appearance','review_palate','review_taste']\n",
    "\n",
    "#Instantiate scaler and one hot encoder\n",
    "##ohe = OneHotEncoder(sparse=False,handle_unknown='ignore')\n",
    "sc = StandardScaler()\n",
    "\n",
    "#Fit and transform columns\n",
    "traindf[num_cols] = sc.fit_transform(traindf[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brewery_id</th>\n",
       "      <th>brewery_name</th>\n",
       "      <th>review_time</th>\n",
       "      <th>review_overall</th>\n",
       "      <th>review_aroma</th>\n",
       "      <th>review_appearance</th>\n",
       "      <th>review_profilename</th>\n",
       "      <th>beer_style</th>\n",
       "      <th>review_palate</th>\n",
       "      <th>review_taste</th>\n",
       "      <th>beer_name</th>\n",
       "      <th>beer_abv</th>\n",
       "      <th>beer_beerid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10325</td>\n",
       "      <td>4886</td>\n",
       "      <td>1234817823</td>\n",
       "      <td>-3.239994</td>\n",
       "      <td>-2.511302</td>\n",
       "      <td>-2.198210</td>\n",
       "      <td>30121</td>\n",
       "      <td>65</td>\n",
       "      <td>-3.317561</td>\n",
       "      <td>-3.162309</td>\n",
       "      <td>34371</td>\n",
       "      <td>5.0</td>\n",
       "      <td>47986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10325</td>\n",
       "      <td>4886</td>\n",
       "      <td>1235915097</td>\n",
       "      <td>-1.148720</td>\n",
       "      <td>-1.792233</td>\n",
       "      <td>-1.384289</td>\n",
       "      <td>30121</td>\n",
       "      <td>51</td>\n",
       "      <td>-1.109519</td>\n",
       "      <td>-1.103587</td>\n",
       "      <td>32297</td>\n",
       "      <td>6.2</td>\n",
       "      <td>48213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10325</td>\n",
       "      <td>4886</td>\n",
       "      <td>1235916604</td>\n",
       "      <td>-1.148720</td>\n",
       "      <td>-1.792233</td>\n",
       "      <td>-1.384289</td>\n",
       "      <td>30121</td>\n",
       "      <td>59</td>\n",
       "      <td>-1.109519</td>\n",
       "      <td>-1.103587</td>\n",
       "      <td>5313</td>\n",
       "      <td>6.5</td>\n",
       "      <td>48215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10325</td>\n",
       "      <td>4886</td>\n",
       "      <td>1234725145</td>\n",
       "      <td>-1.148720</td>\n",
       "      <td>-1.073164</td>\n",
       "      <td>-0.570368</td>\n",
       "      <td>30121</td>\n",
       "      <td>61</td>\n",
       "      <td>-1.845533</td>\n",
       "      <td>-1.103587</td>\n",
       "      <td>34370</td>\n",
       "      <td>5.0</td>\n",
       "      <td>47969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1075</td>\n",
       "      <td>1360</td>\n",
       "      <td>1293735206</td>\n",
       "      <td>0.245463</td>\n",
       "      <td>1.084042</td>\n",
       "      <td>0.243553</td>\n",
       "      <td>22693</td>\n",
       "      <td>9</td>\n",
       "      <td>0.362510</td>\n",
       "      <td>0.955134</td>\n",
       "      <td>8745</td>\n",
       "      <td>7.7</td>\n",
       "      <td>64883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brewery_id  brewery_name  review_time  review_overall  review_aroma  \\\n",
       "0       10325          4886   1234817823       -3.239994     -2.511302   \n",
       "1       10325          4886   1235915097       -1.148720     -1.792233   \n",
       "2       10325          4886   1235916604       -1.148720     -1.792233   \n",
       "3       10325          4886   1234725145       -1.148720     -1.073164   \n",
       "4        1075          1360   1293735206        0.245463      1.084042   \n",
       "\n",
       "   review_appearance  review_profilename  beer_style  review_palate  \\\n",
       "0          -2.198210               30121          65      -3.317561   \n",
       "1          -1.384289               30121          51      -1.109519   \n",
       "2          -1.384289               30121          59      -1.109519   \n",
       "3          -0.570368               30121          61      -1.845533   \n",
       "4           0.243553               22693           9       0.362510   \n",
       "\n",
       "   review_taste  beer_name  beer_abv  beer_beerid  \n",
       "0     -3.162309      34371       5.0        47986  \n",
       "1     -1.103587      32297       6.2        48213  \n",
       "2     -1.103587       5313       6.5        48215  \n",
       "3     -1.103587      34370       5.0        47969  \n",
       "4      0.955134       8745       7.7        64883  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encode categorical features and target\n",
    "\n",
    "# ce.get_embedding_info identifies the categorical variables, # of unique values and embedding size and returns a dictionary\n",
    "embedding_info = ce.get_embedding_info(traindf)\n",
    "embedding_info\n",
    "\n",
    "# ce.get_label_encoded_data integer label encodes the categorical variables and prepares it to feed it to neural network. C\n",
    "#Can do next step of training shallow neural network for embeddings\n",
    "traindf_encoded,encoders = ce.get_label_encoded_data(traindf)\n",
    "\n",
    "traindf_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate features and target\n",
    "\n",
    "\n",
    "target = traindf_encoded['beer_style']\n",
    "feature = traindf_encoded.drop(['brewery_id','review_time','review_profilename','beer_name','beer_abv','beer_beerid','beer_style'], axis=1)\n",
    "\n",
    "\n",
    "#Alternative\n",
    "#featuredf = pd.DataFrame(traindf_encoded)\n",
    "#featuredf.head\n",
    "#cols = [1,2,3,4,5,6]\n",
    "#featuredf = traindf_encoded[traindf_encoded.columns[cols]]\n",
    "\n",
    "\n",
    "#Save locally\n",
    "\n",
    "target.to_csv('../data/processed/target.csv')\n",
    "\n",
    "feature.to_csv('../data/processed/feature.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          brewery_name  review_overall  review_aroma  review_appearance  \\\n",
       "0                4886       -3.239994     -2.511302          -2.198210   \n",
       "1                4886       -1.148720     -1.792233          -1.384289   \n",
       "2                4886       -1.148720     -1.792233          -1.384289   \n",
       "3                4886       -1.148720     -1.073164          -0.570368   \n",
       "4                1360        0.245463      1.084042           0.243553   \n",
       "...               ...             ...           ...                ...   \n",
       "1586609          4617        1.639646      0.364974          -0.570368   \n",
       "1586610          4617        0.245463      1.803111          -2.198210   \n",
       "1586611          4617        0.942555     -0.354095          -1.384289   \n",
       "1586612          4617        0.245463      1.084042           1.057473   \n",
       "1586613          4617        1.639646      1.084042           1.057473   \n",
       "\n",
       "         review_palate  review_taste  \n",
       "0            -3.317561     -3.162309  \n",
       "1            -1.109519     -1.103587  \n",
       "2            -1.109519     -1.103587  \n",
       "3            -1.845533     -1.103587  \n",
       "4             0.362510      0.955134  \n",
       "...                ...           ...  \n",
       "1586609       0.362510      0.268894  \n",
       "1586610      -2.581547      0.268894  \n",
       "1586611      -0.373505      0.268894  \n",
       "1586612       1.098524      0.955134  \n",
       "1586613       1.098524      0.955134  \n",
       "\n",
       "[1518478 rows x 6 columns]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from src.data.splitsets import split_sets_random (ModuleNotFoundError: No module named 'src.data')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_data, X_test, y_data, y_test = train_test_split (feature, target, test_size=0.2, random_state=8)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, test_size=0.2, random_state=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial run - Save split datasets\n",
    "np.save('../data/processed/X_train', X_train)\n",
    "np.save('../data/processed/X_val',   X_val)\n",
    "np.save('../data/processed/X_test',  X_test)\n",
    "np.save('../data/processed/y_train', y_train)\n",
    "np.save('../data/processed/y_val',   y_val)\n",
    "np.save('../data/processed/y_test',  y_test)\n",
    "\n",
    "#Subsequent runs - load saved datasets\n",
    "\n",
    "#X_train = np.load('../data/processed/X_train.npy')\n",
    "#X_val   = np.load('../data/processed/X_val.npy'  )\n",
    "#X_test  = np.load('../data/processed/X_test.npy' )\n",
    "#y_train = np.load('../data/processed/y_train.npy')\n",
    "#y_val   = np.load('../data/processed/y_val.npy'  )\n",
    "#y_test  = np.load('../data/processed/y_test.npy' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define class\n",
    "\n",
    "class PytorchRegression(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(PytorchRegression, self).__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Linear(num_features, 128)\n",
    "        self.layer_out = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(F.relu(self.layer_1(x)))\n",
    "        x = self.layer_out(x)\n",
    "        return (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PytorchRegression(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define functioni to check cuda\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu') # don't have GPU \n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PytorchRegression(\n",
       "  (layer_1): Linear(in_features=6, out_features=128, bias=True)\n",
       "  (layer_out): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model use device (L5.1)\n",
    "device = get_device()\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PytorchRegression(\n",
      "  (layer_1): Linear(in_features=6, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define\n",
    "\n",
    "class PytorchDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Pytorch dataset\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    X_tensor : Pytorch tensor\n",
    "        Features tensor\n",
    "    y_tensor : Pytorch tensor\n",
    "        Target tensor\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    __getitem__(index)\n",
    "        Return features and target for a given index\n",
    "    __len__\n",
    "        Return the number of observations\n",
    "    to_tensor(data)\n",
    "        Convert Pandas Series to Pytorch tensor\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, X, y):\n",
    "        self.X_tensor = self.to_tensor(X)\n",
    "        self.y_tensor = self.to_tensor(y)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_tensor[index], self.y_tensor[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_tensor)\n",
    "    \n",
    "    def to_tensor(self, data):\n",
    "        return torch.Tensor(np.array(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert all sets to Pytorch dataset\n",
    "\n",
    "train_dataset = PytorchDataset(X=X_train, y=y_train)\n",
    "val_dataset = PytorchDataset(X=X_val, y=y_val)\n",
    "test_dataset = PytorchDataset(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define train function\n",
    "\n",
    "def train_regression(train_data, model, criterion, optimizer, batch_size, device, scheduler=None, collate_fn=None):\n",
    "    \"\"\"Train a Pytorch regresssion model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data : torch.utils.data.Dataset\n",
    "        Pytorch dataset\n",
    "    model: torch.nn.Module\n",
    "        Pytorch Model\n",
    "    criterion: function\n",
    "        Loss function\n",
    "    optimizer: torch.optim\n",
    "        Optimizer\n",
    "    bacth_size : int\n",
    "        Number of observations per batch\n",
    "    device : str\n",
    "        Name of the device used for the model\n",
    "    scheduler : torch.optim.lr_scheduler\n",
    "        Pytorch Scheduler used for updating learning rate\n",
    "    collate_fn : function\n",
    "        Function defining required pre-processing steps\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Float\n",
    "        Loss score\n",
    "    Float:\n",
    "        RMSE Score\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    # Create data loader\n",
    "    data = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    \n",
    "    # Iterate through data by batch of observations\n",
    "    for feature, target_class in data:\n",
    "        \n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Load data to specified device\n",
    "        feature, target_class = feature.to(device), target_class.to(device)\n",
    "        \n",
    "        # Make predictions\n",
    "        output = model(feature)\n",
    "        \n",
    "        # Calculate loss for given batch\n",
    "        loss = criterion(output, target_class)\n",
    "        \n",
    "        # Calculate global loss\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Adjust the learning rate\n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "\n",
    "    return train_loss / len(train_data), np.sqrt(train_loss / len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define test function\n",
    "\n",
    "def test_regression(test_data, model, criterion, batch_size, device, collate_fn=None):\n",
    "    \"\"\"Calculate performance of a Pytorch regresssion model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    test_data : torch.utils.data.Dataset\n",
    "        Pytorch dataset\n",
    "    model: torch.nn.Module\n",
    "        Pytorch Model\n",
    "    criterion: function\n",
    "        Loss function\n",
    "    bacth_size : int\n",
    "        Number of observations per batch\n",
    "    device : str\n",
    "        Name of the device used for the model\n",
    "    collate_fn : function\n",
    "        Function defining required pre-processing steps\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Float\n",
    "        Loss score\n",
    "    Float:\n",
    "        RMSE Score\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "\n",
    "    # Create data loader\n",
    "    data = DataLoader(test_data, batch_size=batch_size, collate_fn=collate_fn)\n",
    "    \n",
    "    # Iterate through data by batch of observations\n",
    "    for feature, target_class in data:\n",
    "        \n",
    "        # Load data to specified device\n",
    "        feature, target_class = feature.to(device), target_class.to(device)\n",
    "        \n",
    "        # Set no update to gradients\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # Make predictions\n",
    "            output = model(feature)\n",
    "            \n",
    "            # Calculate loss for given batch\n",
    "            loss = criterion(output, target_class)\n",
    "            \n",
    "            # Calculate global loss\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "    return test_loss / len(test_data), np.sqrt(test_loss / len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 5\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\tLoss: 43.8559\t|\tRMSE: 6.6\n",
      "\t(valid)\tLoss: 35.7507\t|\tRMSE: 6.0\n",
      "Epoch: 1\n",
      "\t(train)\tLoss: 35.3668\t|\tRMSE: 5.9\n",
      "\t(valid)\tLoss: 34.6449\t|\tRMSE: 5.9\n",
      "Epoch: 2\n",
      "\t(train)\tLoss: 34.9896\t|\tRMSE: 5.9\n",
      "\t(valid)\tLoss: 34.7687\t|\tRMSE: 5.9\n",
      "Epoch: 3\n",
      "\t(train)\tLoss: 34.7697\t|\tRMSE: 5.9\n",
      "\t(valid)\tLoss: 34.3569\t|\tRMSE: 5.9\n",
      "Epoch: 4\n",
      "\t(train)\tLoss: 34.6168\t|\tRMSE: 5.9\n",
      "\t(valid)\tLoss: 34.4431\t|\tRMSE: 5.9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_rmse = train_regression(train_dataset, model=model, criterion=criterion, optimizer=optimizer, batch_size=BATCH_SIZE, device=device)\n",
    "    valid_loss, valid_rmse = test_regression(val_dataset, model=model, criterion=criterion, batch_size=BATCH_SIZE, device=device)\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\tLoss: {train_loss:.4f}\\t|\\tRMSE: {train_rmse:.1f}')\n",
    "    print(f'\\t(valid)\\tLoss: {valid_loss:.4f}\\t|\\tRMSE: {valid_rmse:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "torch.save(model, \"../models/pytorch_reg_beer1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 34.4168\t|\tRMSE: 5.9\n"
     ]
    }
   ],
   "source": [
    "#Evaluate\n",
    "\n",
    "test_loss, test_rmse = test_regression(test_dataset, model=model, criterion=criterion, batch_size=BATCH_SIZE, device=device)\n",
    "print(f'\\tLoss: {test_loss:.4f}\\t|\\tRMSE: {test_rmse:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spare\n",
    "\n",
    "#df.loc[df['brewery_id'] == 27]\n",
    "\n",
    "from joblib import dump\n",
    "dump(reg,  '../models/linear_poly_2.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
